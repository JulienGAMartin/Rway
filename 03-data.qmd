# Data {#sec-data-r}

Until now, you've created fairly simple data in R and stored it as a vector (@sec-funcs).
However, most (if not all) of you will have much more complicated datasets from your various experiments and surveys that go well beyond what a vector can handle.
Learning how R deals with different types of data and data structures, how to import your data into R and how to manipulate and summarize your data are some of the most important skills you will need to master.

In this Chapter we'll go over the main data types in R and focus on some of the most common data structures.
We will also cover how to import data into R from an external file, how to manipulate (wrangle) and summarize data and finally how to export data from R to an external file.

## Data types

Understanding the different types of data and how R deals with these data is important.
The temptation is to glaze over and skip these technical details, but beware, this can come back to bite you somewhere unpleasant if you don't pay attention.
We've already seen an example (@sec-r-objs) of this when we tried (and failed) to add two character objects together using the `+` operator.

R has six basic types of data; numeric, integer, logical, complex and character.
The keen eyed among you will notice we've only listed five data types here, the final data type is raw which we won't cover as it's not useful 99.99% of the time.
We also won't cover complex numbers, but will let you [imagine][complex_num] that part!


  - **Numeric** data are numbers that contain a decimal.
Actually they can also be whole numbers but we'll gloss over that.

  - **Integers** are whole numbers (those numbers without a decimal point).

  - **Logical** data take on the value of either `TRUE` or `FALSE`.
There's also another special type of logical called `NA` to represent missing values.

  - **Character** data are used to represent string values.
You can think of character strings as something like a word (or multiple words).
A special type of character string is a *factor*, which is a string but with additional attributes (like levels or an order).
We'll cover factors later.


R is (usually) able to automatically distinguish between different classes of data by their nature and the context in which they're used although you should bear in mind that R can't actually read your mind and you may have to explicitly tell R how you want to care a data type.
You can find out the type (or class) of any object using the `class()` function.

```{r}
#| echo: true
#| eval: true
num <- 2.2
class(num)

char <- "hello"
class(char)

logi <- TRUE
class(logi)
```

Alternatively, you can ask if an object is a specific class using using a logical test.
The `is.[classOfData]()` family of functions will return either a `TRUE` or a `FALSE`.

```{r}
#| echo: true
#| eval: true
is.numeric(num)

is.character(num)

is.character(char)

is.logical(logi)
```

It can sometimes be useful to be able to change the class of a variable using the `as.[className]()` family of coercion functions, although you need to be careful when doing this as you might receive some unexpected results (see what happens below when we try to convert a character string to a numeric).
 
```{r}
#| echo: true
#| eval: true
# coerce numeric to character
class(num)
num_char <- as.character(num)
num_char
class(num_char)

# coerce character to numeric!
class(char)
char_num <- as.numeric(char)
```

Here's a summary table of some of the logical test and coercion functions available to you.

|     Type       |    Logical test       |     Coercing       |
|:--------------:|:-------------------:|:-----------------:|
|  Character     |   `is.character`   |   `as.character`   |
|  Numeric   |   `is.numeric`   |   `as.numeric`   |
|  Logical | `is.logical` | `as.logical` |
|  Factor   |   `is.factor`  |   `as.factor`  |
|  Complex     |   `is.complex`    |   `as.complex`    |

## Data structures

Now that you've been introduced to some of the most important classes of data in R, let’s have a look at some of main structures that we have for storing these data.

### Scalars and vectors {#sec-scal-vecs}

Perhaps the simplest type of data structure is the vector.
You've already been introduced to vectors in @sec-funcs although some of the vectors you created only contained a single value.
Vectors that have a single value (length 1) are called scalars.
Vectors can contain numbers, characters, factors or logicals, but the key thing to remember is that all the elements inside a vector must be of the same class.
In other words, vectors can contain either numbers, characters or logical but not mixtures of these types of data.
There is one important exception to this, you can include `NA` (remember this is special type of logical) to denote missing data in vectors with other data types.


```{r}
#| label: fig-data_struc
#| fig-cap: Scalar and vector data structure
#| echo: false
#| out-width: 40%
#| fig-align: center
knitr::include_graphics(path = "images/data/scal_vec.png")
```

### Matrices and arrays {#sec-mat-array}

Another useful data structure used in many disciplines such as population ecology, theoretical and applied statistics is the matrix.
A matrix is simply a vector that has additional attributes called dimensions.
Arrays are just multidimensional matrices.
Again, matrices and arrays must contain elements all of the same data class.


```{r}
#| label: fig-data_struc2
#| fig-cap: Matrix and array data structure
#| echo: false
#| out-width: 50%
#| fig-align: center
knitr::include_graphics(path = "images/data/mat_array.png")
```


A convenient way to create a matrix or an array is to use the `matrix()` and `array()` functions respectively.
Below, we will create a matrix from a sequence 1 to 16 in four rows (`nrow = 4`) and fill the matrix row-wise (`byrow = TRUE`) rather than the default column-wise.
When using the `array()` function we define the dimensions using the `dim =` argument, in our case 2 rows, 4 columns in 2 different matrices.
  

```{r}
#| echo: true
#| eval: true
my_mat <- matrix(1:16, nrow = 4, byrow = TRUE)
my_mat

my_array <- array(1:16, dim = c(2, 4, 2))
my_array
```

Sometimes it's also useful to define row and column names for your matrix but this is not a requirement.
To do this use the `rownames()` and `colnames()` functions.

```{r}
#| echo: true
#| eval: true
rownames(my_mat) <- c("A", "B", "C", "D")
colnames(my_mat) <- c("a", "b", "c", "d")
my_mat
```

Once you've created your matrices you can do useful stuff with them and as you'd expect, R has numerous built in functions to perform matrix operations.
Some of the most common are given below.
For example, to transpose a matrix we use the transposition function `t()`

```{r}
#| echo: true
#| eval: true
my_mat_t <- t(my_mat)
my_mat_t
```

To extract the diagonal elements of a matrix and store them as a vector we can use the `diag()` function

```{r}
#| echo: true
#| eval: true
my_mat_diag <- diag(my_mat)
my_mat_diag
```

The usual matrix addition, multiplication etc can be performed.
Note the use of the `%*%` operator to perform matrix multiplication.

```{r}
#| echo: true
#| eval: true
mat.1 <- matrix(c(2, 0, 1, 1), nrow = 2) # notice that the matrix has been filled
mat.1 # column-wise by default

mat.2 <- matrix(c(1, 1, 0, 2), nrow = 2)
mat.2

mat.1 + mat.2 # matrix addition
mat.1 * mat.2 # element by element products
mat.1 %*% mat.2 # matrix multiplication
```

### Lists {#sec-lists}

The next data structure we will quickly take a look at is a list.
Whilst vectors and matrices are constrained to contain data of the same type, lists are able to store mixtures of data types.
In fact we can even store other data structures such as vectors and arrays within a list or even have a list of a list.
This makes for a very flexible data structure which is ideal for storing irregular or non-rectangular data (see @sec-prog-r for an example).

To create a list we can use the `list()` function.
Note how each of the three list elements are of different classes (character, logical, and numeric) and are of different lengths.

```{r}
#| echo: true
#| eval: true
list_1 <- list(
  c("black", "yellow", "orange"),
  c(TRUE, TRUE, FALSE, TRUE, FALSE, FALSE),
  matrix(1:6, nrow = 3)
)
list_1
```

Elements of the list can be named during the construction of the list 

```{r}
#| echo: true
#| eval: true
list_2 <- list(
  colours = c("black", "yellow", "orange"),
  evaluation = c(TRUE, TRUE, FALSE, TRUE, FALSE, FALSE),
  time = matrix(1:6, nrow = 3)
)
list_2
```

or after the list has been created using the `names()` function

```{r}
#| echo: true
#| eval: true
names(list_1) <- c("colours", "evaluation", "time")
list_1
```

### Data frames {#sec-df}

By far the most commonly used data structure to store data in is the data frame.
A data frame is a powerful two-dimensional object made up of rows and columns which looks superficially very similar to a matrix.
However, whilst matrices are restricted to containing data all of the same type, data frames can contain a mixture of different types of data.
Typically, in a data frame each row corresponds to an individual observation and each column corresponds to a different measured or recorded variable.
This setup may be familiar to those of you who use LibreOffice Calc or Microsoft Excel to manage and store your data.
Perhaps a useful way to think about data frames is that they are essentially made up of a bunch of vectors (columns) with each vector containing its own data type but the data type can be different between vectors.

As an example, the data frame below contains the results of an experiment to determine the effect of parental care (with or without) of unicorns (*Unicornus magnificens*) on offsprings growth under 3 different food availability regime.
The data frame has 8 variables (columns) and each row represents an individual unicorn.
The variables `care` and `food` are factors ([categorical][cat-var] variables).
The `p_care` variable has 2 levels (`care` and `no_care`) and the `food` level variable has 3 levels (`low`, `medium` and `high`).
The variables `height`, `weight`, `mane_size` and `fluffyness` are numeric and the variable `horn_rings` is an integer representing the number of rings on the horn.
Although the variable `block` has numeric values, these do not really have any order and could also be treated as a factor (i.e.
they could also have been called A and B).


```{r}
#| label: tbl-import-data
#| echo: false
#| message: false
#| tbl-cap: Imported unicorn data
library(kableExtra)
unicorns <- read.csv("data/unicorns.csv")
knitr::kable(rbind(head(unicorns), tail(unicorns)), row.names = FALSE, booktabs = TRUE)
```


There are a couple of important things to bear in mind about data frames.
These types of objects are known as rectangular data (or tidy data) as each column must have the same number of observations.
Also, any missing data should be recorded as an `NA` just as we did with our vectors.

We can construct a data frame from existing data objects such as vectors using the `data.frame()` function.
As an example, let's create three vectors `p.height`, `p.weight` and `p.names` and include all of these vectors in a data frame object called `dataf`.

```{r}
#| label: dataf
#| echo: true
p.height <- c(180, 155, 160, 167, 181)
p.weight <- c(65, 50, 52, 58, 70)
p.names <- c("Joanna", "Charlotte", "Helen", "Karen", "Amy")

dataf <- data.frame(height = p.height, weight = p.weight, names = p.names)
dataf
```

You'll notice that each of the columns are named with variable name we supplied when we used the `data.frame()` function.
It also looks like the first column of the data frame is a series of numbers from one to five.
Actually, this is not really a column but the name of each row.
We can check this out by getting R to return the dimensions of the `dataf` object using the `dim()` function.
We see that there are 5 rows and 3 columns.

```{r}
#| label: dataf2
#| echo: true
dim(dataf) # 5 rows and 3 columns
```

Another really useful function which we use all the time is `str()` which will return a compact summary of the structure of the data frame object (or any object for that matter).

```{r}
#| label: dataf3
#| echo: true
str(dataf)
```

The `str()` function gives us the data frame dimensions and also reminds us that `dataf` is a `data.frame` type object.
It also lists all of the variables (columns) contained in the data frame, tells us what type of data the variables contain and prints out the first five values.
We often copy this summary and place it in our R scripts with comments at the beginning of each line so we can easily refer back to it whilst writing our code.
We showed you how to comment blocks in RStudio @sec-proj-doc.

Also notice that R has automatically decided that our `p.names` variable should be a character (`chr`) class variable when we first created the data frame.
Whether this is a good idea or not will depend on how you want to use this variable in later analysis.
If we decide that this wasn't such a good idea we can change the default behaviour of the `data.frame()` function by including the argument `stringsAsFactors = TRUE`.
Now our strings are automatically converted to factors.

```{r}
#| label: dataf4
#| echo: true
p.height <- c(180, 155, 160, 167, 181)
p.weight <- c(65, 50, 52, 58, 70)
p.names <- c("Joanna", "Charlotte", "Helen", "Karen", "Amy")

dataf <- data.frame(
  height = p.height, weight = p.weight, names = p.names,
  stringsAsFactors = TRUE
)
str(dataf)
```


## Importing data

Although creating data frames from existing data structures is extremely useful, by far the most common approach is to create a data frame by importing data from an external file.
To do this, you'll need to have your data correctly formatted and saved in a file format that R is able to recognize.
Fortunately for us, R is able to recognize a wide variety of file formats, although in reality you'll probably end up only using two or three regularly.


### Saving files to import

The easiest method of creating a data file to import into R is to enter your data into a spreadsheet using either Microsoft Excel or LibreOffice Calc and save the spreadsheet as a comma delimited file.
We prefer LibreOffice Calc as it's open source, platform independent and free but MS Excel is OK too (but see [here][excel_gotcha] for some gotchas).
Here's the data from the petunia experiment we discussed previously displayed in LibreOffice.
If you want to follow along you can download the data file (*'unicorn.xlsx'*) from @sec-data-files.
  


```{r}
#| label: fig-LO-calc0
#| fig-cap: Unicorn data in LibreOffice Calc
#| echo: false
#| out-width: 60%
#| fig-align: center
knitr::include_graphics(path = "images/data/libre_off.png")
```


For those of you unfamiliar with the tab delimited file format it simply means that data in different columns are separated with a ',' character and is usually saved as a file with a '.csv' extension.

To save a spreadsheet as a comma delimited file in LibreOffice Calc select `File` -> `Save as ...` from the main menu.
You will need to specify the location you want to save your file in the 'Save in folder' option and the name of the file in the 'Name' option.
In the drop down menu located above the 'Save' button change the default 'All formats' to 'Text CSV (.csv)'.


```{r}
#| label: fig-LO-calc
#| fig-cap: Choosing `csv` format when saving with LibreOffice Calc
#| echo: false
#| out-width: 60%
#| fig-align: center
knitr::include_graphics(path = "images/data/libre_off1.png")
```


Click the Save button and then select the 'Use Text CSV Format' option.
Click on OK to save the file.


There are a couple of things to bear in mind when saving files to import into R which will make your life easier in the long run.
Keep your column headings (if you have them) short and informative.
Also avoid spaces in your column headings by replacing them with an underscore or a dot (i.e.
replace `mane size` with `mane size` or `mane.size`) and avoid using special characters (i.e.
`leaf area (mm^2)` or uppercase to simpy your life).
Remember, if you have missing data in your data frame (empty cells) you should use an `NA` to represent these missing values or have an empty cell.
This will keep the data frame tidy.

### Import functions {#sec-import-fnc}

Once you've saved your data file in a suitable format we can now read this file into R.
The workhorse function for importing data into R is the `read.table()` function (we discuss some alternatives later in the chapter).
The `read.table()` function is a very flexible function with a shed load of arguments (see `?read.table`) but it's quite simple to use.
Let's import a comma delimited file called `unicorns.csv` which contains the data we saw previously in this Chapter (@sec-df) and assign it to an object called `unicorns`.
The file is located in a `data` directory which itself is located in our root directory (@sec-dir-struc).
The first row of the data contains the variable (column) names.
To use the `read.table()` function to import this file

```{r}
#| label: df1
#| echo: true
unicorns <- read.table(
  file = "data/unicorns.csv", header = TRUE, sep = ",", dec = ".",
  stringsAsFactors = TRUE
)
```

There are a few things to note about the above command.
First, the file path and the filename (including the file extension) needs to be enclosed in either single or double quotes (i.e.
the `data/unicorns.txt` bit) as the `read.table()` function expects this to be a character string.
If your working directory is already set to the directory which contains the file, you don’t need to include the entire file path just the filename.
In the example above, the file path is separated with a single forward slash `/`.
This will work regardless of the operating system you are using and we recommend you stick with this.
However, Windows users may be more familiar with the single backslash notation and if you want to keep using this you will need to include them as double backslashes.

::: {.callout-warning}
Note though that the double backslash notation will **not** work on computers using Mac OSX or Linux operating systems.
We thus strongly discourage it since it is not reproducible
:::

The `header = TRUE` argument specifies that the first row of your data contains the variable names (i.e.
`food`, `block` etc).
If this is not the case you can specify `header = FALSE` (actually, this is the default value so you can omit this argument entirely).
The `sep = ","` argument tells R what is file delimiter.

Other useful arguments include `dec =` and `na.strings =`.
The `dec =` argument allows you to change the default character (`.`) used for a decimal point.
This is useful if you're in a country where decimal places are usually represented by a comma (i.e.
`dec = ","`).
The `na.strings =` argument allows you to import data where missing values are represented with a symbol other than `NA`.
This can be quite common if you are importing data from other statistical software such as Minitab which represents missing values as a `*` (`na.strings = "*"`).

Honestly, from the `read.table()` a series of predefined functions are available.
They are all using `read.table()` but define format specific options.
We can simply `read.csv()`to read a csv file, with "," separation and "." for decimals.
In countries were "," is used for decimals, csv files use ";" as a separator. 
In this case using `read.csv2()` would be needed.
When working with tab delimited files, the functions `read.delim()` and `read.delim2()`
can be used with "." and "," as decimal respectively.
 

After importing our data into R , to see the contents of the data frame we could just type the name of the object as we have done previously.
**BUT** before you do that, think about why you're doing this.
If your data frame is anything other than tiny, all you're going to do is fill up your Console with data.
It's not like you can easily check whether there are any errors or that your data has been imported correctly.
A much better solution is to use our old friend the `str()` function to return a compact and informative summary of your data frame.

```{r}
#| label: df3
#| echo: true
str(unicorns)
```

Here we see that `unicorns` is a 'data.frame' object which contains 96 rows and 8 variables (columns).
Each of the variables are listed along with their data class and the first 10 values.
As we mentioned previously in this Chapter, it can be quite convenient to copy and paste this into your R script as a comment block for later reference.

Notice also that your character string variables (`care` and `food`) have been imported as factors because we used the argument `stringsAsFactors = TRUE`.
If this is not what you want you can prevent this by using the `stringsAsFactors = FALSE` or from R version 4.0.0 you can just leave out this argument as `stringsAsFactors = FALSE` is the default.

```{r}
#| label: df4
#| echo: true
unicorns <- read.delim(file = "data/unicorns.txt")
str(unicorns)
```

If we just wanted to see the names of our variables (columns) in the data frame we can use the `names()` function which will return a character vector of the variable names.

```{r}
#| label: df4.1
#| echo: true
names(unicorns)
```

You can even import spreadsheet files from MS Excel or other statistics software directly into R but our advice is that this should generally be avoided if possible as it just adds a layer of uncertainty between you and your data.
In our opinion it's almost always better to export your spreadsheets as tab or comma delimited files and then import them into R using one of the `read.table()` derivative function.
If you're hell bent on directly importing data from other software you will need to install the `foreign` package which has functions for importing Minitab, SPSS, Stata and SAS files. For MS Excel and LO Calc spreadsheets, there are a few packages that can be used.

### Common import frustrations

It's quite common to get a bunch of really frustrating error messages when you first start importing data into R.
Perhaps the most common is

```r
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'unicorns.txt': No such file or directory
```

This error message is telling you that R cannot find the file you are trying to import.
It usually rears its head for one of a couple of reasons (or all of them!).
The first is that you've made a mistake in the spelling of either the filename or file path.
Another common mistake is that you have forgotten to include the file extension in the filename (i.e.
`.txt`).
Lastly, the file is not where you say it is or you've used an incorrect file path.
Using RStudio Projects (@sec-rsprojs) and having a logical directory structure (@sec-dir-struc) goes a long way to avoiding these types of errors.

Another really common mistake is to forget to include the `header = TRUE` argument when the first row of the data contains variable names.
For example, if we omit this argument when we import our `unicorns.txt` file everything looks OK at first (no error message at least)

```{r}
#| label: df6
#| echo: true
unicorns_bad <- read.table(file = "data/unicorns.txt", sep = "\t")
```

but when we take a look at our data frame using `str()`

```{r}
#| label: df7
#| echo: true
str(unicorns_bad)
```

We can see an obvious problem, all of our variables have been imported as factors and our variables are named `V1`, `V2`, `V3` ...
`V8`.
The problem happens because we haven't told the `read.table()` function that the first row contains the variable names and so it treats them as data.
As soon as we have a single character string in any of our data vectors, R treats the vectors as character type data (remember all elements in a vector must contain the same type of data (@sec-scal-vecs)).

This is just one more argument to use `read.csv()` or `read.delim()` function with appropriate default values for arguments.

### Other import options {#sec-import-other}

There are numerous other functions to import data from a variety of sources and formats.
Most of these functions are contained in packages that you will need to install before using them.
We list a couple of the more useful packages and functions below.

The `fread()` function from the `read.table` package is great for importing large data files quickly and efficiently (much faster than the `read.table()` function).
One of the great things about the `fread()` function is that it will automatically detect many of the arguments you would normally need to specify (like `sep =` etc).
One of the things you will need to consider though is that the `fread()` function will return a `data.table` object not a `data.frame` as would be the case with the `read.table()` function.
This is usually not a problem as you can pass a `data.table` object to any function that only accepts `data.frame` objects.
To learn more about the differences between `data.table` and `data.frame` objects see [here][data-table].

```{r}
#| label: df8
#| echo: true
#| eval: false
library(read.table)
all_data <- fread(file = "data/unicorns.txt")
```

Various functions from the `readr` package are also very efficient at reading in large data files.
The `readr` package is part of the '[tidyverse][tidyverse]' collection of packages and provides many equivalent functions to base R for importing data.
The `readr` functions are used in a similar way to the `read.table()` or `read.csv()` functions and many of the arguments are the same (see `?readr::read_table` for more details).
There are however some differences.
For example, when using the `read_table()` function the `header = TRUE` argument is replaced by `col_names = TRUE` and the function returns a `tibble` class object which is the tidyverse equivalent of a `data.frame` object (see [here][tibbles] for differences).

```{r}
#| label: df9
#| echo: true
#| eval: false
library(readr)
# import white space delimited files
all_data <- read_table(file = "data/unicorns.txt", col_names = TRUE)

# import comma delimited files
all_data <- read_csv(file = "data/unicorns.txt")

# import tab delimited files
all_data <- read_delim(file = "data/unicorns.txt", delim = "\t")

# or use
all_data <- read_tsv(file = "data/unicorns.txt")
```

If your data file is ginormous, then the `ff` and `bigmemory` packages may be useful as they both contain import functions that are able to store large data in a memory efficient manner.
You can find out more about these functions [here][ff] and [here][bigmem].


## Wrangling data frames

Now that you're able to successfully import your data from an external file into R our next task is to do something useful with our data.
Working with data is a fundamental skill which you'll need to develop and get comfortable with as you'll likely do a lot of it during any project.
The good news is that R is especially good at manipulating, summarising and visualising data.
Manipulating data (often known as data wrangling or munging) in R can at first seem a little daunting for the new user but if you follow a few simple logical rules then you'll quickly get the hang of it, especially with some practice.
 


Let's remind ourselves of the structure of the `unicorns` data frame we imported in the previous section.

```{r}
#| label: dw1
#| echo: true
unicorns <- read.table(file = "data/unicorns.txt", header = TRUE, sep = "\t")
str(unicorns)
```

To access the data in any of the variables (columns) in our data frame we can use the `$` notation.
For example, to access the `height` variable in our `unicorns` data frame we can use `unicorns$height`.
This tells R that the `height` variable is contained within the data frame `unicorns`.

```{r}
#| label: dw2
#| echo: true
unicorns$height
```

This will return a vector of the `height` data.
If we want we can assign this vector to another object and do stuff with it, like calculate a mean or get a summary of the variable using the `summary()` function.

```{r}
#| label: dw3
#| echo: true
f_height <- unicorns$height
mean(f_height)
summary(f_height)
```

Or if we don't want to create an additional object we can use functions 'on-the-fly' to only display the value in the console.

```{r}
#| label: dw3.1
#| echo: true
mean(unicorns$height)
summary(unicorns$height)
```

Just as we did with vectors (@sec-vectors), we also can access data in data frames using the square bracket `[ ]` notation.
However, instead of just using a single index, we now need to use two indexes, one to specify the rows and one for the columns.
To do this, we can use the notation `my_data[rows, columns]` where `rows` and `columns` are indexes and `my_data` is the name of the data frame.
Again, just like with our vectors our indexes can be positional or the result of a logical test.

### Positional indexes

To use positional indexes we simple have to write the position of the rows and columns we want to extract inside the `[ ]`.
For example, if for some reason we wanted to extract the first value (1^st^ row ) of the `height` variable (4^th^ column)

```{r}
#| label: dw4
#| echo: true
unicorns[1, 4]

# this would give you the same
unicorns$height[1]
```

We can also extract values from multiple rows or columns by specifying these indexes as vectors inside the `[ ]`.
To extract the first 10 rows and the first 4 columns we simple supply a vector containing a sequence from 1 to 10 for the rows index (`1:10`) and a vector from 1 to 4 for the column index (`1:4`).

```{r}
#| label: dw5
#| echo: true
unicorns[1:10, 1:4]
```

Or for non sequential rows and columns then we can supply vectors of positions using the `c()` function.
To extract the 1^st^, 5^th^, 12^th^, 30^th^ rows from the 1^st^, 3^rd^, 6^th^ and 8^th^ columns

```{r}
#| label: dw6
#| echo: true
unicorns[c(1, 5, 12, 30), c(1, 3, 6, 8)]
```

All we are doing in the two examples above is creating vectors of positions for the rows and columns that we want to extract.
We have done this by using the skills we developed in @sec-funcs when we generated vectors using the `c()` function or using the `:` notation.

But what if we want to extract either all of the rows or all of the columns? It would be extremely tedious to have to generate vectors for all rows or for all columns.
Thankfully R has a shortcut.
If you don't specify either a row or column index in the `[ ]` then R interprets it to mean you want all rows or all columns.
For example, to extract the first 4 rows and all of the columns in the `unicorns` data frame

```{r}
unicorns[1:4, ]
```

or all of the rows and the first 3 columns[^1].

[^1]: For space and simplicity we are just showing the first and last five rows

```r
unicorns[, 1:3]
```

```{r}
#| label: dw8
#| echo: false
rbind(head(unicorns[, 1:3], n = 5), tail(unicorns[, 1:3], n = 5))
```

We can even use negative positional indexes to exclude certain rows and columns.
As an example, lets extract all of the rows except the first 85 rows and all columns except the 4^th^, 7^th^ and 8^th^ columns.
Notice we need to use `-()` when we generate our row positional vectors.
If we had just used `-1:85` this would actually generate a regular sequence from -1 to 85 which is not what we want (we can of course use `-1:-85`).

```{r}
#| label: dw9
#| echo: true
unicorns[-(1:85), -c(4, 7, 8)]
```

In addition to using a positional index for extracting particular columns (variables) we can also name the variables directly when using the square bracket `[ ]` notation.
For example, let's extract the first 5 rows and the variables `care`, `food` and `mane_size`.
Instead of using `unicorns[1:5, c(1, 2, 6)]` we can instead use

```{r}
#| label: dw10
#| echo: true
unicorns[1:5, c("p_care", "food", "mane_size")]
```

We often use this method in preference to the positional index for selecting columns as it will still give us what we want even if we've changed the order of the columns in our data frame for some reason.

### Logical indexes

Just as we did with vectors, we can also extract data from our data frame based on a logical test.
We can use all of the logical operators that we used for our vector examples so if these have slipped your mind maybe have a look at @sec-logical-index and refresh your memory.
 Let's extract all rows where `height` is greater than 12 and extract all columns by default (remember, if you don't include a column index after the comma it means all columns).

```{r}
#| label: dw11
#| echo: true
big_unicorns <- unicorns[unicorns$height > 12, ]
big_unicorns
```

Notice in the code above that we need to use the `unicorns$height` notation for the logical test.
If we just named the `height` variable without the name of the data frame we would receive an error telling us R couldn't find the variable `height`.
The reason for this is that the `height` variable only exists inside the `unicorns` data frame so you need to tell R exactly where it is.

```r
big_unicorns <- unicorns[height > 12, ]
Error in `[.data.frame`(unicorns, height > 12, ) : 
  object 'height' not found
```

So how does this work? The logical test is `unicorns$height > 12` and R will only extract those rows that satisfy this logical condition.
If we look at the output of just the logical condition you can see this returns a vector containing `TRUE` if `height` is greater than 12 and `FALSE` if `height` is not greater than 12.

```{r}
#| label: dw13
#| echo: true
unicorns$height > 12
```

So our row index is a vector containing either `TRUE` or `FALSE` values and only those rows that are `TRUE` are selected.

Other commonly used operators are shown below

```{r}
#| label: dw14
#| echo: true
#| eval: false
unicorns[unicorns$height >= 6, ] # values greater or equal to 6

unicorns[unicorns$height <= 6, ] # values less than or equal to 6

unicorns[unicorns$height == 8, ] # values  equal to 8

unicorns[unicorns$height != 8, ] # values  not equal to 8
```

We can also extract rows based on the value of a character string or factor level.
Let's extract all rows where the `food` level is equal to `high` (again we will output all columns).
Notice that the double equals `==` sign must be used for a logical test and that the character string must be enclosed in either single or double quotes (i.e.
`"high"`).

```{r}
#| label: dw15
#| echo: true
#| eval: true
food_high <- unicorns[unicorns$food == "high", ]
rbind(head(food_high, n = 10), tail(food_high, n = 10))
```

Or we can extract all rows where `food` level is not equal to `medium` (using `!=`) and only return columns 1 to 4.

```{r}
#| label: dw16
#| echo: true
#| eval: true
food_not_medium <- unicorns[unicorns$food != "medium", 1:4]
rbind(head(food_not_medium, n = 10), tail(food_not_medium, n = 10))
```


We can increase the complexity of our logical tests by combining them with [Boolean expressions][boolean] just as we did for vector objects.
For example, to extract all rows where `height` is greater or equal to `6` AND `food` is equal to `medium` AND `care` is equal to `no_care` we combine a series of logical expressions with the `&` symbol.

```{r}
#| label: dw17
#| echo: true
low_no_care_heigh6 <- unicorns[unicorns$height >= 6 & unicorns$food == "medium" &
  unicorns$p_care == "no_care", ]
low_no_care_heigh6
```

To extract rows based on an 'OR' Boolean expression we can use the `|` symbol.
Let's extract all rows where `height` is greater than 12.3 OR less than 2.2.

```{r}
#| label: dw17.1
#| echo: true
height2.2_12.3 <- unicorns[unicorns$height > 12.3 | unicorns$height < 2.2, ]
height2.2_12.3
```

An alternative method of selecting parts of a data frame based on a logical expression is to use the `subset()` function instead of the `[ ]`.
The advantage of using `subset()` is that you no longer need to use the `$` notation when specifying variables inside the data frame as the first argument to the function is the name of the data frame to be subsetted.
The disadvantage is that `subset()` is less flexible than the `[ ]` notation.

```{r}
#| label: dw18
#| echo: true
care_med_2 <- subset(unicorns, p_care == "care" & food == "medium" & block == 2)
care_med_2
```

And if you only want certain columns you can use the `select =` argument.

```{r}
#| label: dw19
#| echo: true
uni_p_care <- subset(unicorns, p_care == "care" & food == "medium" & block == 2,
  select = c("p_care", "food", "mane_size")
)
uni_p_care
```

### Ordering data frames

Remember when we used the function `order()` to order one vector based on the order of another vector (way back in @sec-vec-ord).
This comes in very handy if you want to reorder rows in your data frame.
For example, if we want all of the rows in the data frame `unicorns` to be ordered in ascending value of `height` and output all columns by default.


```{r}
#| label: dw20
#| echo: true
#| eval: true
height_ord <- unicorns[order(unicorns$height), ]
head(height_ord, n = 10)
```

We can also order by descending order of a variable (i.e.
`mane_size`) using the `decreasing = TRUE` argument.

```{r}
#| label: dw21
#| echo: true
#| eval: true
mane_size_ord <- unicorns[order(unicorns$mane_size, decreasing = TRUE), ]
head(mane_size_ord, n = 10)
```

We can even order data frames based on multiple variables.
For example, to order the data frame `unicorns` in ascending order of both `block` and `height`.

```{r}
#| label: dw22
#| echo: true
#| eval: true
block_height_ord <- unicorns[order(unicorns$block, unicorns$height), ]
head(block_height_ord, n = 10)
```


What if we wanted to order `unicorns` by ascending order of `block` but descending order of `height`? We can use a simple trick by adding a `-` symbol before the `unicorns$height` variable when we use the `order()` function.
This will essentially turn all of the `height` values negative which will result in reversing the order.
Note, that this trick will only work with numeric variables.

```{r}
#| label: dw23
#| echo: true
#| eval: true
block_revheight_ord <- unicorns[order(unicorns$block, -unicorns$height), ]
rbind(head(block_revheight_ord, n = 10), tail(block_revheight_ord, n = 10))
```

If we wanted to do the same thing with a factor (or character) variable like `food` we would need to use the function `xtfrm()` for this variable inside our `order()` function.

```{r}
#| label: dw24
#| echo: true
#| eval: true
block_revheight_ord <- unicorns[order(-xtfrm(unicorns$food), unicorns$height), ]
rbind(head(block_revheight_ord, n = 10), tail(block_revheight_ord, n = 10))
```

Notice that the `food` variable has been reverse ordered alphabetically and `height` has been ordered by increasing values within each level of `food`.

If we wanted to order the data frame by `food` but this time order it from `low` -> `medium` -> `high` instead of the default alphabetically (`high`, `low`, `medium`), we need to first change the order of our levels of the `food` factor in our data frame using the `factor()` function.
Once we've done this we can then use the `order()` function as usual.
Note, if you're reading the pdf version of this book, the output has been truncated to save space.

```{r}
#| label: dw24a
#| echo: true
#| eval: true
unicorns$food <- factor(unicorns$food,
  levels = c("low", "medium", "high")
)
food_ord <- unicorns[order(unicorns$food), ]
rbind(head(food_ord, n = 10), tail(food_ord, n = 10))
```

### Adding columns and rows

Sometimes it's useful to be able to add extra rows and columns of data to our data frames.
There are multiple ways to achieve this (as there always is in R!) depending on your circumstances.
To simply append additional rows to an existing data frame we can use the `rbind()` function and to append columns the `cbind()` function.
Let's create a couple of test data frames to see this in action using our old friend the `data.frame()` function.

```{r}
#| label: dw25
#| echo: true
# rbind for rows
df1 <- data.frame(
  id = 1:4, height = c(120, 150, 132, 122),
  weight = c(44, 56, 49, 45)
)
df1

df2 <- data.frame(
  id = 5:6, height = c(119, 110),
  weight = c(39, 35)
)
df2

df3 <- data.frame(
  id = 1:4, height = c(120, 150, 132, 122),
  weight = c(44, 56, 49, 45)
)
df3

df4 <- data.frame(location = c("UK", "CZ", "CZ", "UK"))
df4
```

We can use the `rbind()` function to append the rows of data in `df2` to the rows in `df1` and assign the new data frame to `df_rcomb`.

```{r}
#| label: dw25.1
#| echo: true
df_rcomb <- rbind(df1, df2)
df_rcomb
```

And `cbind` to append the column in `df4` to the `df3` data frame and assign to df_ccomb`.

```{r}
#| label: dw25.2
#| echo: true
df_ccomb <- cbind(df3, df4)
df_ccomb
```

Another situation when adding a new column to a data frame is useful is when you want to perform some kind of transformation on an existing variable.
For example, say we wanted to apply a log~10~ transformation on the height variable in the `df_rcomb` data frame we created above.
We could just create a separate variable to contains these values but it's good practice to create this variable as a new column inside our existing data frame so we keep all of our data together.
Let's call this new variable `height_log10`.
 

```{r}
#| label: dw26
#| echo: true
# log10 transformation
df_rcomb$height_log10 <- log10(df_rcomb$height)
df_rcomb
```

This situation also crops up when we want to convert an existing variable in a data frame from one data class to another data class.
For example, the `id` variable in the `df_rcomb` data frame is numeric type data (use the `str()` or `class()` functions to check for yourself).
If we wanted to convert the `id` variable to a factor to use later in our analysis we can create a new variable called `Fid` in our data frame and use the `factor()` function to convert the `id` variable.

```{r}
#| label: dw27
#| echo: true
# convert to a factor
df_rcomb$Fid <- factor(df_rcomb$id)
df_rcomb
str(df_rcomb)
```

### Merging data frames

Instead of just appending either rows or columns to a data frame we can also merge two data frames together.
Let's say we have one data frame that contains taxonomic information on some common UK rocky shore invertebrates (called `taxa`) and another data frame that contains information on where they are usually found on the rocky shore (called `zone`).
We can merge these two data frames together to produce a single data frame with both taxonomic and location information.
Let's first create both of these data frames (in reality you would probably just import your different datasets).

```{r}
#| label: dw28
#| echo: true
taxa <- data.frame(
  GENUS = c("Patella", "Littorina", "Halichondria", "Semibalanus"),
  species = c("vulgata", "littoria", "panacea", "balanoides"),
  family = c("patellidae", "Littorinidae", "Halichondriidae", "Archaeobalanidae")
)
taxa

zone <- data.frame(
  genus = c(
    "Laminaria", "Halichondria", "Xanthoria", "Littorina",
    "Semibalanus", "Fucus"
  ),
  species = c(
    "digitata", "panacea", "parietina", "littoria",
    "balanoides", "serratus"
  ),
  zone = c("v_low", "low", "v_high", "low_mid", "high", "low_mid")
)
zone
```

Because both of our data frames contains at least one variable in common (`species` in our case) we can simply use the `merge()` function to create a new data frame called `taxa_zone`.

```{r}
#| label: dw29
#| echo: true
taxa_zone <- merge(x = taxa, y = zone)
taxa_zone
```

Notice that the merged data frame contains only the rows that have `species` information in **both** data frames.
There are also two columns called `GENUS` and `genus` because the `merge()` function treats these as two different variables that originate from the two data frames.

If we want to include all data from both data frames then we will need to use the `all = TRUE` argument.
The missing values will be included as `NA`.

```{r}
#| label: dw30
#| echo: true
taxa_zone <- merge(x = taxa, y = zone, all = TRUE)
taxa_zone
```

If the variable names that you want to base the merge on are different in each data frame (for example `GENUS` and `genus`) you can specify the names in the first data frame (known as `x`) and the second data frame (known as `y`) using the `by.x =` and `by.y =` arguments.

```{r}
#| label: dw31
#| echo: true
taxa_zone <- merge(x = taxa, y = zone, by.x = "GENUS", by.y = "genus", all = TRUE)
taxa_zone
```

Or using multiple variable names.

```{r}
#| label: dw31.1
#| echo: true
taxa_zone <- merge(
  x = taxa, y = zone, by.x = c("species", "GENUS"),
  by.y = c("species", "genus"), all = TRUE
)
taxa_zone
```

### Reshaping data frames {#sec-reshape}

Reshaping data into different formats is a common task.
With rectangular type data (data frames have the same number of rows in each column) there are two main data frame shapes that you will come across: the 'long' format (sometimes called stacked) and the 'wide' format.
An example of a long format data frame is given below.
We can see that each row is a single observation from an individual subject and each subject can have multiple rows.
This results in a single column of our `measurement`.

```{r}
#| label: dw32
#| echo: true
long_data <- data.frame(
  subject = rep(c("A", "B", "C", "D"), each = 3),
  sex = rep(c("M", "F", "F", "M"), each = 3),
  condition = rep(c("control", "cond1", "cond2"), times = 4),
  measurement = c(
    12.9, 14.2, 8.7, 5.2, 12.6, 10.1, 8.9,
    12.1, 14.2, 10.5, 12.9, 11.9
  )
)
long_data
```


We can also format the same data in the wide format as shown below.
In this format we have multiple observations from each subject in a single row with measurements in different columns (`control`, `cond1` and `cond2`).
This is a common format when you have repeated measurements from sampling units.

```{r}
#| label: dw34
#| echo: true
wide_data <- data.frame(
  subject = c("A", "B", "C", "D"),
  sex = c("M", "F", "F", "M"),
  control = c(12.9, 5.2, 8.9, 10.5),
  cond1 = c(14.2, 12.6, 12.1, 12.9),
  cond2 = c(8.7, 10.1, 14.2, 11.9)
)
wide_data
```


Whilst there's no inherent problem with either of these formats we will sometimes need to convert between the two because some functions will require a specific format for them to work.
The most common format is the long format.

There are many ways to convert between these two formats but we'll use the `melt()` and `dcast()` functions from the `reshape2` package (you will need to install this package first).
The `melt()` function is used to convert from wide to long formats.
The first argument for the `melt()` function is the data frame we want to melt (in our case `wide_data`).
The `id.vars = c("subject", "sex")` argument is a vector of the variables you want to stack, the `measured.vars = c("control", "cond1", "cond2")` argument identifies the columns of the measurements in different conditions, the `variable.name = "condition"` argument specifies what you want to call the stacked column of your different conditions in your output data frame and `value.name = "measurement"` is the name of the column of your stacked measurements in your output data frame.

```{r}
#| label: dw36
#| echo: true
library(reshape2)
wide_data # remind ourselves what the wide format looks like

# convert wide to long
my_long_df <- melt(
  data = wide_data, id.vars = c("subject", "sex"),
  measured.vars = c("control", "cond1", "cond2"),
  variable.name = "condition", value.name = "measurement"
)
my_long_df
```

The `dcast()` function is used to convert from a long format data frame to a wide format data frame.
The first argument is again is the data frame we want to cast (`long_data` for this example).
The second argument is in formula syntax.
The `subject + sex` bit of the formula means that we want to keep these columns separate, and the `~ condition` part is the column that contains the labels that we want to split into new columns in our new data frame.
The `value.var = "measurement"` argument is the column that contains the measured data.
 

```{r}
#| label: dw37
#| echo: true
long_data # remind ourselves what the long format look like

# convert long to wide
my_wide_df <- dcast(
  data = long_data, subject + sex ~ condition,
  value.var = "measurement"
)
my_wide_df
```

## Introduction to the `tidyverse`

it seems it is not super tidy in here and we need to improve that

## Summarising data frames

Now that we're able to manipulate and extract data from our data frames our next task is to start exploring and getting to know our data.
In this section we'll start producing tables of useful summary statistics of the variables in our data frame and in the next two Chapters we'll cover visualising our data with base R graphics and using the `ggplot2` package.

A really useful starting point is to produce some simple summary statistics of all of the variables in our `unicorns` data frame using the `summary()` function.

```{r}
#| label: sum1
#| echo: true
summary(unicorns)
```

For numeric variables (i.e.
`height`, `weight` etc) the mean, minimum, maximum, median, first (lower) quartile and third (upper) quartile are presented.
For factor variables (i.e.
`care` and `food`) the number of observations in each of the factor levels is given.
If a variable contains missing data then the number of `NA` values is also reported.

If we wanted to summarise a smaller subset of variables in our data frame we can use our indexing skills in combination with the `summary()` function.
For example, to summarise only the `height`, `weight`, `mane_size` and `fluffyness` variables we can include the appropriate column indexes when using the `[ ]`.
Notice we include all rows by not specifying a row index.
 

```{r}
#| label: sum2
#| echo: true
summary(unicorns[, 4:7])

# or equivalently
# summary(unicorns[, c("height", "weight", "mane_size", "fluffyness")])
```

And to summarise a single variable.

```{r}
#| label: sum3
#| echo: true
summary(unicorns$mane_size)

# or equivalently
# summary(unicorns[, 6])
```

As you've seen above, the `summary()` function reports the number of observations in each level of our factor variables.
Another useful function for generating tables of counts is the `table()` function.
The `table()` function can be used to build contingency tables of different combinations of factor levels.
For example, to count the number of observations for each level of `food`

```{r}
#| label: sum4
#| echo: true
table(unicorns$food)
```

We can extend this further by producing a table of counts for each combination of `food` and `care` factor levels.

```{r}
#| label: sum5
#| echo: true
table(unicorns$food, unicorns$p_care)
```

A more flexible version of the `table()` function is the `xtabs()` function.
The `xtabs()` function uses a formula notation (`~`) to build contingency tables with the cross-classifying variables separated by a `+` symbol on the right hand side of the formula.
`xtabs()` also has a useful `data =` argument so you don't have to include the data frame name when specifying each variable.

```{r}
#| label: sum6
#| echo: true
xtabs(~ food + p_care, data = unicorns)
```

We can even build more complicated contingency tables using more variables.
Note, in the example below the `xtabs()` function has quietly coerced our `block` variable to a factor.

```{r}
#| label: sum7
#| echo: true
xtabs(~ food + p_care + block, data = unicorns)
```

And for a nicer formatted table we can nest the `xtabs()` function inside the `ftable()` function to 'flatten' the table.

```{r}
#| label: sum8
#| echo: true
ftable(xtabs(~ food + p_care + block, data = unicorns))
```

We can also summarise our data for each level of a factor variable.
Let's say we want to calculate the mean value of `height` for each of our `low`, `meadium` and `high` levels of `food`.
To do this we will use the `mean()` function and apply this to the `height` variable for each level of `food` using the `tapply()` function.

```{r}
#| label: sum9
#| echo: true
tapply(unicorns$height, unicorns$food, mean)
```

The `tapply()` function is not just restricted to calculating mean values, you can use it to apply many of the functions that come with R or even functions you've written yourself (see @sec-prog-r for more details).
For example, we can apply the `sd()` function to calculate the standard deviation for each level of `food` or even the `summary()` function.

```{r}
#| label: sum10
#| echo: true
tapply(unicorns$height, unicorns$food, sd)
tapply(unicorns$height, unicorns$food, summary)
```

Note, if the variable you want to summarise contains missing values (`NA`) you will also need to include an argument specifying how you want the function to deal with the `NA` values.
We saw an example if this in @sec-na-vals where the `mean()` function returned an `NA` when we had missing data.
To include the `na.rm = TRUE` argument we simply add this as another argument when using `tapply()`.

```{r}
#| label: sum11
#| echo: true
tapply(unicorns$height, unicorns$food, mean, na.rm = TRUE)
```

We can also use `tapply()` to apply functions to more than one factor.
The only thing to remember is that the factors need to be supplied to the `tapply()` function in the form of a list using the `list()` function.
To calculate the mean `height` for each combination of `food` and `care` factor levels we can use the `list(unicorns$food, unicorns$p_care)` notation.

```{r}
#| label: sum12
#| echo: true
tapply(unicorns$height, list(unicorns$food, unicorns$p_care), mean)
```

And if you get a little fed up with having to write `unicorns$` for every variable you can nest the `tapply()` function inside the `with()` function.
The `with()` function allows R to evaluate an R expression with respect to a named data object (in this case `unicorns`).
 

```{r}
#| label: sum13
#| echo: true
with(unicorns, tapply(height, list(food, p_care), mean))
```

The `with()` function also works with many other functions and can save you alot of typing!

Another really useful function for summarising data is the `aggregate()` function.
The `aggregate()` function works in a very similar way to `tapply()` but is a bit more flexible.

For example, to calculate the mean of the variables `height`, `weight`, `mane_size` and `fluffyness` for each level of `food`.

```{r}
#| label: sum14
#| echo: true
aggregate(unicorns[, 4:7], by = list(food = unicorns$food), FUN = mean)
```

In the code above we have indexed the columns we want to summarise in the `unicorns` data frame using `unicorns[, 4:7]`.
The `by =` argument specifies a list of factors (`list(food = unicorns$food)`) and the `FUN =` argument names the function to apply (`mean` in this example).

Similar to the `tapply()` function we can include more than one factor to apply a function to.
Here we calculate the mean values for each combination of `food` and `care`

```{r}
#| label: sum15
#| echo: true
aggregate(unicorns[, 4:7], by = list(
  food = unicorns$food,
  p_care = unicorns$p_care
), FUN = mean)
```

We can also use the `aggregate()` function in a different way by using the formula method (as we did with `xtabs()`).
On the left hand side of the formula (`~`) we specify the variable we want to apply the mean function on and to the right hand side our factors separated by a `+` symbol.
The formula method also allows you to use the `data =` argument for convenience.
 

```{r}
#| label: sum16
#| echo: true
aggregate(height ~ food + p_care, FUN = mean, data = unicorns)
```

One advantage of using the formula method is that we can also use the `subset =` argument to apply the function to subsets of the original data.
For example, to calculate the mean `height` for each combination of the `food` and `care` levels but only for those unicorns that have less than 7 `horn_rings`.

```{r}
#| label: sum17
#| echo: true
aggregate(height ~ food + p_care, FUN = mean, subset = horn_rings < 7, data = unicorns)
```

Or for only those unicorns in `block` 1.

```{r}
#| label: sum18
#| echo: true
aggregate(height ~ food + p_care, FUN = mean, subset = block == "1", data = unicorns)
```

## Exporting data

By now we hope you're getting a feel for how powerful and useful R is for manipulating and summarising data (and we've only really scratched the surface).
One of the great benefits of doing all your data wrangling in R is that you have a permanent record of all the things you've done to your data.
Gone are the days of making undocumented changes in Excel or Calc! By treating your data as 'read only' and documenting all of your decisions in R you will have made great strides towards making your analysis more reproducible and transparent to others.
It's important to realise, however, that any changes you've made to your data frame in R will not change the original data file you imported into R (and that's a good thing).
Happily it's straightforward to export data frames to external files in a wide variety of formats.

### Export functions

The main workhorse function for exporting data frames is the `write.table()` function.
As with the `read.table()` function, the `write.table()` function is very flexible with lots of arguments to help customise it's behaviour.
As an example, let's take our original `unicorns` data frame, do some useful stuff to it and then export these changes to an external file.

Similarly to `read.table()`, `write.table()` has a series of function with format specific default values such as `write.csv()` and `write.delim()` which use "," and tabs as delimiters, respectively,and include column names by default. 

Let's order the rows in the data frame in ascending order of `height` within each level `food`.
We will also apply a square root transformation on the number of horn rings variable (`horn_rings`) and a log~10~ transformation on the `height` variable and save these as additional columns in our data frame (hopefully this will be somewhat familiar to you!).

```{r}
#| label: export1
#| echo: true
unicorns_df2 <- unicorns[order(unicorns$food, unicorns$height), ]
unicorns_df2$horn_rings_sqrt <- sqrt(unicorns_df2$horn_rings)
unicorns_df2$log10_height <- log10(unicorns_df2$height)
str(unicorns_df2)
```

Now we can export our new data frame `unicorns_df2` using the `write.table()` function.
The first argument is the data frame you want to export (`unicorns_df2` in our example).
We then give the filename (with file extension) and the file path in either single or double quotes using the `file =` argument.
In this example we're exporting the data frame to a file called `unicorns_transformed.csv` in the `data` directory.
The `row.names = FALSE` argument stops R from including the row names in the first column of the file.


```{r}
#| label: export2
#| echo: true
#| eval: false
write.csv(unicorns_df2,
  file = "data/unicorns_transformed.csv", 
  row.names = FALSE
)
```

As we saved the file as a comma delimited text file we could open this file in any text editor.

We can of course export our files in a variety of other formats.

### Other export functions

As with importing data files into R, there are also many alternative functions for exporting data to external files beyond the `write.table()` function.
If you followed the 'Other import functions' @sec-import-other of this Chapter you will already have the required packages installed.

The `fwrite()` function from the `read.table` package is very efficient at exporting large data objects and is much faster than the `write.table()` function.
It's also quite simple to use as it has most of the same arguments as `write.table()`.
To export a tab delimited text file we just need to specify the data frame name, the output file name and file path and the separator between columns.

```{r}
#| label: export5
#| echo: true
#| eval: false
library(read.table)
fwrite(unicorns_df2, file = "data/unicorns_04_12.txt", sep = "\t")
```

To export a csv delimited file it's even easier as we don't even need to include the `sep =` argument.

```{r}
#| label: export6
#| echo: true
#| eval: false
library(read.table)
fwrite(unicorns_df2, file = "data/unicorns_04_12.csv")
```

The `readr` package also comes with two useful functions for quickly writing data to external files: the `write_tsv()` function for writing tab delimited files and the `write_csv()` function for saving comma separated values (csv) files.

```{r}
#| label: export7
#| echo: true
#| eval: false
library(readr)
write_tsv(unicorns_df2, path = "data/unicorns_04_12.txt")

write_csv(unicorns_df2, path = "data/unicorns_04_12.csv")
```


```{r}
#| label: links
#| child: images/_links.md
```

